---
title: "STAT 331 Portfolio"
author: "Devin Hadley"
format:
  html:
    theme: minty
embed-resources: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Example 1

```{r}
#| label: wd-1-csv-1

# From Lab 2 Question 1
# Loading a CSV using the here library.

surveys <- read_csv(here::here("Week 2", "Labs", "Lab 2", "surveys.csv"))

```

-   `csv` Example 2

```{r}
#| label: wd-1-csv-2

# From Lab 4
# Loading a CSV via a URL.

childcare_costs <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv')
```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

# From Practice Activity 4
# Loading an xslx in google colab.

military <- read_xlsx("gov_spending_per_capita.xlsx",
                      sheet = "Share of Govt. spending",
                      skip  = 7,
                      n_max = 190,
                      na = c(". .", "xxx", "..")
                      )

```

**WD-2: I can select necessary columns from a dataset.**

-   Example selecting specified columns

```{r}
#| label: wd-2-ex-1

# From Lab 3 Question 5
# Here I used to select to explicity "grab" the specified columns.

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 9) |>
  mutate(
    across(c(academic_degree,
             sex,
             weekday,
             course_id,
             teacher_id,
             question_no),
           as.factor),
  ) |>
  select(
    course_id,
    teacher_id,
    question_no,
    no_participants,
    resp_share,
    SET_score_avg,
    percent_failed_cur,
    academic_degree,
    seniority,
    sex
  )

```

-   Example removing specified columns

```{r}
#| label: wd-2-ex-2

# PA 5.3 Question 3

# In this problem I remove the mark column from the fish data set by combinig select with the negation operator. I did this because mark wasn't a necessary column for our analysis.

# This solution was modified from the original solution, I realised I could reduce the size of the table we store in memory by discarding unused columns in the beginning.

fish <- fish |>
  select(-mark)

missing_summary <- fish |>
  summarise(across(everything(), 
                   ~ sum(is.na(.x)), 
                   .names = "{col}_missing"))
```

-   Example selecting columns based on logical values (e.g., `starts_with()`, `ends_with()`, `contains()`, `where()`)

```{r}
#| label: wd-2-ex-3

# From Lab 10 Question 8
# In this problem is use starts_with("conf") inside of select in order to include the conf.low and conf.high in the final table.

mycifun <- function(beta0, beta1, n) {
  
  x = runif(n = n, min = 0, max = 1)
  
  ep = rnorm(n = n, mean = 0, sd = 1)
  
  y = beta0 + beta1 * x + ep
  
  obs_data <- data.frame(x = x, y = y)
  
  fit <- lm(y ~ x, data = obs_data)
  
  tidy(fit, conf.int = TRUE) |>
    filter(term == "x") |>
    mutate(cover = ifelse(conf.low <= beta1 & beta1 <= conf.high,
                          1,
                          0
                          )) |>
    select(estimate,
           starts_with("conf"),
           cover)
  
}

```

\

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-3-numeric-ex-1

# From Lab 3 Question 5
# Here I filtered based on whether the no_participants column contains a value greater than nine.

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 9) |>
  mutate(
    across(c(academic_degree,
             sex,
             weekday,
             course_id,
             teacher_id,
             question_no),
           as.factor),
  ) |>
  select(
    course_id,
    teacher_id,
    question_no,
    no_participants,
    resp_share,
    SET_score_avg,
    percent_failed_cur,
    academic_degree,
    seniority,
    sex
  )

```

-   Numeric Example 2

```{r}
#| label: wd-3-numeric-ex-2

# From Challenge 3, Question 1
# Here I filter the teacher evaluations to only include those which are question 3.

teacher_evals_compare <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(
    SET_level = if_else(SET_score_avg >= 4,
                        "excellent",
                        "standard"),
    sen_level = case_when(
      seniority <= 4          ~ "junior",
      seniority <= 8          ~ "senior",
      TRUE                    ~ "very senior"
    )
  ) |>
  select(course_id, SET_level, sen_level)
```

-   Character Example 1 (any context)

```{r}
#| label: wd-3-character

# From lab 5.
# Here I filter based string equality.


gold_members_who_checked_in_on_9th <- get_fit_now_check_in |>
  filter(check_in_date == 20180109) |>
  select(membership_id) |>
  rename(id = membership_id) |>
  inner_join(get_fit_now_member) |>
  filter(membership_status == "gold")

```

-   Character Example 2 (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

# From lab 5.
# Here I filter using str_detect to get strings which contain H42W.

person |>
  semi_join(gold_members_who_checked_in_on_9th,
            by = c("id" = "person_id")) |>
  inner_join(drivers_license, by = c("license_id" = "id")) |>
  filter(str_detect(plate_number, "H42W"))

```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

# From lab 5.
# Here I convert the date using mutate and lubridate, and then filter based on month and year

final_suspect <- facebook_event_checkin |>
  mutate(date = ymd(date)) |>
  filter(year(date) == 2017,
         month(date) == 12,
         event_name == "SQL Symphony Concert")|>
  group_by(person_id) |>
  filter(n() == 3) |>
  inner_join(women_matching_description, by = c("person_id" = "id"))

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-4-numeric-ex-1

# Lab 3 question 7
# Here I create a new column called percentage for each sex by dividing the count for that sex by the total count of all teachers and multiplying by 100.

teacher_evals_clean |>
  distinct(teacher_id, .keep_all = TRUE) |>
  count(sex, name = "count") |>
  mutate(percentage = count / sum(count) * 100)


```

-   Numeric Example 2

```{r}
#| label: wd-4-numeric-ex-2

# Lab 3 question 10
# Here I create a new variable called num_courses which is an integer represnting the number of distinct courses a teacher teaches.

teacher_evals_clean |>
  group_by(teacher_id) |>
  mutate(num_courses = n_distinct(course_id)) |>
  filter(question_no == 901) |>
  summarize(
    num_courses = first(num_courses),
    avg_q1_score = mean(SET_score_avg, na.rm = TRUE)
  ) |>
  ungroup() |>
  filter(num_courses >= 5) |>
  filter(avg_q1_score == min(avg_q1_score) | avg_q1_score == max(avg_q1_score))

```

-   Factor Example 1 (renaming levels)

```{r}
#| label: wd-4-factor-ex-1

# Lab 4 Question 4

# Here is rename the county_name factor by collapsing them into a smaller subset of factors. This effectively renames many counties into their corresponding larger county. 

# This solution was revised from its initial submission. I removed the initial mutate for just county_name, and moved it into the mutate for collapsing into the region as an aditional argument.

ca_childcare <- ca_childcare |> 
  mutate(
    county_name = str_remove(county_name, " County"),
    region = fct_collapse(county_name,
      "Superior California" = superior_counties,
      "North Coast" = north_coast_counties,
      "San Francisco" = san_fran_counties,
      "Northern San Joaquin" = n_san_joaquin_counties,
      "Central Coast" = central_coast_counties,
      "Southern San Joaquin" = s_san_joaquin_counties,
      "Inland Empire" = inland_counties,
      "Los Angeles" = la_county,
      "Orange County" = orange_county,
      "San Diego Imperial" = san_diego_imperial_counties
    )
  )

```

-   Factor Example 2 (reordering levels)

```{r}
#| label: wd-4-factor-ex-2

# Lab 4 Question 7
# Here is an example where I modify the existing age_group and region facors. More specifically, the factors are reordered using fct_relevel which explicitly defines an ordering and fct_reorder which reorders the region factor based on its corresponding 2018 median income (another variable).

long_childcare_data <- left_join(ca_childcare, income_table, by="region") |>
  select(study_year,
         region,
         mc_infant,
         mc_toddler,
         mc_preschool,
         `Median Income 2018`) |>
  pivot_longer(
    cols = starts_with("mc"),
    names_to = "age_group",
    values_to = "price"
  ) |>
  mutate(
    age_group = fct_recode(age_group,
    "Infant" = "mc_infant",
    "Toddler" = "mc_toddler",
    "Preschool" = "mc_preschool"
    ),
    age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
    region = fct_reorder(region, `Median Income 2018`, .desc = TRUE)
  )
```

\

\

-   Character (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

# Lab 9 Question 5

# In this code, within the mutate() call, str_to_title() is used via fct_relabel() to convert the Sex column's levels to title.

evals_factors |>
  distinct(teacher_id, .keep_all = TRUE) |>
  select(
    `Academic Degree` = academic_degree,
    Seniority = seniority,
    Sex = sex
  ) |>
    mutate(
    `Academic Degree` = fct_recode(`Academic Degree`,
      "Doctorate" = "dr",
      "Masters" = "ma",
      "No Degree" = "no_dgr",
      "Tenured Professor" = "prof"
    ),
    Seniority = case_when(
      Seniority <= 4 ~ "Junior",
      Seniority <= 8 ~ "Senior",
      TRUE ~ "Very Senior"
    ),
    Sex = fct_relabel(Sex, str_to_title)
  ) |>
  pivot_longer(
    cols = everything(), 
    names_to = "variable", 
    values_to = "level"
  ) |>
  count(variable, level) |>
  group_by(variable) |>
  mutate(prop = n / sum(n)) |>
  ungroup() |>
  kable() |>
  kable_styling(full_width = FALSE,
                bootstrap_options = "striped")

```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

# From Lab 5.
# Here I modified an existing variable which was an integer representation of a date (i.e. 20180101) into a lubridate so that I could filter by date properties later on.

final_suspect <- facebook_event_checkin |>
  mutate(date = ymd(date)) |>
  filter(year(date) == 2017,
         month(date) == 12,
         event_name == "SQL Symphony Concert")|>
  group_by(person_id) |>
  filter(n() == 3) |>
  inner_join(women_matching_description, by = c("person_id" = "id"))


```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()` Example 1

```{r}
#| label: wd-5-left-ex-1

# From Lab 5
# Here I did a left join because even if there was no correponding income data for the person, I still wanted to keep their record as income wasn't that vital to the investigation.

women_matching_description <- person |>
  inner_join(drivers_license, by = c("license_id" = "id")) |>
  left_join(income, by = "ssn") |>
  filter(gender == "female",
         height %in% c(65, 66, 67),
         hair_color == "red",
         car_make == "Tesla",
         car_model == "Model S")

```

-   `right_join()` Example 1

```{r}
#| label: wd-5-right

# Lab 5
# I modified this problem from using inner_join to right_join as a proof of concept.
# For this problem I wanted to join member check ins with the membership status.
# Right join here will preserve all the check ins on the 9th regardless whether it 
# has a corresponding member in get_fit_now members. However any NA entries are still
# filtered out by checking for membership_status == "gold".

gold_members_who_checked_in_on_9th <- get_fit_now_member |>
  right_join(
    get_fit_now_check_in |>
      filter(check_in_date == 20180109) |>
      select(membership_id) |>
      rename(id = membership_id)
  ) |>
  filter(membership_status == "gold")

```

-   `left_join()` **or** `right_join()` Example 2

```{r}
#| label: wd-5-left-right-ex-2

# Lab 5
# I modified this problem from using inner_join to left_join as a proof of concept.
# For this problem I wanted to join member check ins with the membership status.
# Left join here will preserve all the check ins on the 9th regardless whether it 
# has a corresponding member in get_fit_now members. However any NA entries are still
# filtered out by checking for membership_status == "gold".

gold_members_who_checked_in_on_9th <- get_fit_now_check_in |>
  filter(check_in_date == 20180109) |>
  select(membership_id) |>
  rename(id = membership_id) |>
  left_join(get_fit_now_member) |>
  filter(membership_status == "gold")

```

\

-   `inner_join()` Example 1

```{r}
#| label: wd-5-inner-ex-1

# Lab 5
# Here I wanted to find gold members who checked in on the 9th and also had a plate number including H42W.
# Inner join was especially useful as I only wanted the rows with a match in both tables since I am connecting them logically.

person |>
  semi_join(gold_members_who_checked_in_on_9th, by = c("id" = "person_id")) |>
  inner_join(drivers_license, by = c("license_id" = "id")) |>
  filter(str_detect(plate_number, "H42W"))

```

-   `inner_join()` Example 2

```{r}
#| label: wd-5-inner-ex-2

# Lab 4 Question 2

# Here I used an inner join as it only made sense in the context of the assignment to analyze counties with corresponding childcare cost data. Thus there is no reason to include counties without costs or costs without a corresponding county in our dataframe.

ca_childcare <- 
  inner_join(counties, childcare_costs, by = "county_fips_code") |>
  filter(state_abbreviation == "CA")

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

# Lab 5,
# Here I used a semi join in order to filter the persons table based on the gold members who checked in on the 9th. More specifically, I only kept persons who's id appeared in the gold members who checked in on the 9th person_id column.

gold_members_who_checked_in_on_9th <- get_fit_now_check_in |>
  filter(check_in_date == 20180109) |>
  select(membership_id) |>
  rename(id = membership_id) |>
  left_join(get_fit_now_member) |>
  filter(membership_status == "gold")

person |>
  semi_join(gold_members_who_checked_in_on_9th, by = c("id" = "person_id")) |>
  inner_join(drivers_license, by = c("license_id" = "id")) |>
  filter(str_detect(plate_number, "H42W"))

```

-   `anti_join()`

```{r}
#| label: wd-6-anti

# From Lab 5

# Here I use an anti join to find extract which of the final suspects are innocent and which is guilty so I can indepentendly display them later.


# This question was modified from its previous submission. I made it so the ouput differaeniated between which of the women matching the description went to the sympony and which of the women did not which made anti join useful.

   symphony_goers <- facebook_event_checkin |>
     mutate(date = ymd(date)) |>
     filter(year(date) == 2017, month(date) == 12, event_name == "SQL Symphony Concert") |>
     group_by(person_id) |>
     filter(n() == 3)
   
   cleared_suspect <- women_matching_description |>
     anti_join(symphony_goers, by = c("id" = "person_id"))
   
   accomplice <- women_matching_description |>
     semi_join(symphony_goers, by = c("id" = "person_id"))

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

# Challenge 4
# Here I used pivot longer to convert the summary table, which was in a wide format (multiple variables in one column) into a tidy / long format where center type and median price become their own columns. This made it far easier to plot later on.

summary_table_long <- summary_table |>
  pivot_longer(
    cols = c("median_center_price", "median_family_price"),
    names_to = "care_type",
    values_to = "median_price"
  ) |>
  mutate(
    care_type = fct_recode(care_type,
      "Center-Based" = "median_center_price",
      "Family-Based" = "median_family_price"
    ) |>
      fct_relevel("Family-Based", "Center-Based")
  )
  

ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) ...

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

# Lab 4 Question 5
# Here I used pivot_wider to transform the long format summary dataframe of median incomes for each region and year into a wide, human-readable table, creating separate "Median Income 2008" and "Median Income 2018".

income_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(
    median_income = median(me_2018),
  ) |>
  ungroup() |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_prefix = "Median Income "
  ) |>
  arrange(desc(`Median Income 2018`))
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

The following assignments satisfy the above criteria:

-   Lab 2
-   Lab 3
-   Lab 9
-   Lab 10

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

# From Challenge 4
# Here I have a documented ggplot which uses pipes with a single function per line to eludicate the modifications to the plot clearly. I added the documentations after the fact.

# I display a line plot showing the change in median childcare costs over time,
# highlighting the gap between center-based and family-based care.
ggplot(summary_table_long,
       aes(x = study_year,
           y = median_price,
           color = care_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_ribbon(data = summary_table,
              aes(x = study_year,
                  ymin = median_family_price,
                  ymax = median_center_price,
                  group = 1),
              fill = "skyblue", alpha = 0.3, inherit.aes = FALSE) +
  labs(
    title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
    subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
    x = "Year",
    y = "Median Weekly Price (2018 Dollars)",
    color = "Type of Childcare"
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(margin = margin(b = 10)),
    axis.title = element_text(face = "bold"),
    plot.background = element_rect(color = "black", linewidth = 1) 
  )

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2


# From Challenge 4
# Here I have a tidy, and documented dplyr pipeline. It avoids redundant calls, creates a tidy table, and is readable. I added the documentations after the fact.

# I pivot the wide summary table into a tidy, long summary table which allows us to easily plot median price for center and family based infant childcare.
summary_table_long <- summary_table |>
  pivot_longer(
    cols = c("median_center_price", "median_family_price"),
    names_to = "care_type",
    values_to = "median_price"
  ) |>
  mutate(
    care_type = fct_recode(care_type,
      "Center-Based" = "median_center_price",
      "Family-Based" = "median_family_price"
    ) |>
      fct_relevel("Family-Based", "Center-Based")
  )

```

-   Example of function formatting

```{r}
#| label: r-2-3

# Lab 8, Question 2
# Here is an example of a well documented and tidy function. Its name and parameters describes exactly what it does and the code itself is structured well.

pivot_table <- function(df, row_var, col_var) {
  
  if (!is.data.frame(df)) {
    stop("The first argument 'df' must be a data frame.")
  }
  
  df |>
    count({{ row_var }}, {{ col_var }}) |>
    pivot_wider(
      names_from = {{ col_var }},
      values_from = n,
      values_fill = 0
    ) |>
    adorn_totals(where = c("row", "col"))
    
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example (any context)

```{r}
#| label: r-3-example


# From Lab 8, Question 3
# This function uses tidy evaluation ({{ }} and enquo()) to accept flexible column inputs and format_name() to automatically create readable labels, making it robust against varying column naming conventions and input styles.


format_name <- function(var_quo) {
    
    var_name <- rlang::as_name(var_quo)
    var_name |>
      str_replace_all("_", " ") |>
      str_to_title()
    
}

create_colored_scatterplot <- function(df, x_var, y_var) {
  
  x_var_quo <- enquo(x_var)
  y_var_quo <- enquo(y_var)
  
  x_lab <- format_name(x_var_quo)
  y_lab <- format_name(y_var_quo)
  
  ggplot(
    data = df,
    mapping = aes(x = {{ x_var }}, y = {{ y_var }})
  ) +
    geom_point(
      mapping = aes(color = {{ y_var }}), 
      show.legend = FALSE,
      alpha = 0.8
    ) +
    scale_color_viridis_c() +
    labs(
      title = paste(y_lab, "vs.", x_lab),
      x = x_lab,
      y = y_lab,
    ) +
    theme_minimal()
}

```

-   Example (function stops)

```{r}
#| label: r-3-function-stops

# From Lab 8 Question, 3

# This function uses guards which call stop if the vector is non numeric or the vector is of 1 or 0. This makes it resistant to bad inputs.


rescale_01 <- function(vector) {
  
  if (!is.numeric(vector)) {
    stop("Input vector must be numeric.")
  }
  
  if (length(vector) <= 1) {
    stop("Input vector must have more than one element to calculate a range.")
  }
  
  min_val <- min(vector, na.rm = TRUE)
  max_val <- max(vector, na.rm = TRUE)
  
  (vector - min_val) / (max_val - min_val)
}


```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   At least two numeric variables

```{r}
#| label: dvs-1-num


# Lab 2 Question 4
# Here I plotted hindfoot_length (numerical) against weight (numerical). It is also faceted by species which is categorical.

ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = hindfoot_length)) +
 geom_point(alpha=0.3) + facet_wrap(~ species) + labs(x = "Weight (g)", y = "",
 title ="Scatterplot of Hindfoot Length vs Weight of Various Species",
 subtitle = "Hindfoot Length (mm)")


```

-   At least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

# From Challenge 2
# Here I used ggplot to create boxplots of weight (numerical) by species (categorical).

ggplot(data = surveys, mapping = aes(x = weight, y = species)) +
  geom_boxplot(outliers = FALSE,
               orientation = "y",
               aes(color = sex)) +
  scale_colour_viridis_d() +
  geom_jitter(alpha=0.1, color="steelblue") +
  labs(x = "Weight (g)",
       y = "Species",
       title = "Distribution of Weight by Species")

```

-   At least two categorical variables

```{r}
#| label: dvs-2-cat

# Challenge 3 Question 2

# This ggplot displays the weekly median costs (numerical) per year faceted by childcare type (categorical) and colored by region (categotical).

#   This problem displays a plot where sen_level (seniority level, e.g., "junior", "senior") is a categorical variable mapped to the x-axis. SET_level (SET score level, e.g., "excellent", "standard") is a categorical variable mapped to the fill aesthetic.


# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#ba945c", "excellent" = "#b796d4")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )



```

-   Dates (time series plot)

```{r}
#| label: dvs-2-date


# Lab 4 Question 7

# This ggplot displays the weekly median costs (numerical) per year (timeseries) faceted by childcare type (categorical) and colored by region (categotical).

# 1.) Color by region.
# 2.) Facet by age group.


long_childcare_data <- left_join(ca_childcare, income_table, by="region") |>
  select(study_year,
         region,
         mc_infant,
         mc_toddler,
         mc_preschool,
         `Median Income 2018`) |>
  pivot_longer(
    cols = starts_with("mc"),
    names_to = "age_group",
    values_to = "price"
  ) |>
  mutate(
    age_group = fct_recode(age_group,
    "Infant" = "mc_infant",
    "Toddler" = "mc_toddler",
    "Preschool" = "mc_preschool"
    ),
    age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
    region = fct_reorder(region, `Median Income 2018`, .desc = TRUE)
  )


pallete <- colorRampPalette(brewer.pal(7, "Accent"))(10)

ggplot(long_childcare_data, aes(x = study_year, y = price, color = region)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", alpha = 0.5) +
  facet_wrap(~ age_group, ncol=3) +
  labs(
    title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = NULL,
    color = "California Region"
  ) +
  scale_x_continuous(breaks = seq(from = 2008, to = 2018, by = 2)) +
  scale_color_manual(values = pallete) +
  theme(aspect.ratio = 1)


```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can modify my plot theme to be more readable

```{r}
#| label: dvs-2-ex-1

# From Challenge 4
# Here I used the minimal theme to make the plot more clear and thus easier to read.

summary_table_long <- summary_table |>
  pivot_longer(
    cols = c("median_center_price", "median_family_price"),
    names_to = "care_type",
    values_to = "median_price"
  ) |>
  mutate(
    care_type = fct_recode(care_type,
      "Center-Based" = "median_center_price",
      "Family-Based" = "median_family_price"
    ) |>
      fct_relevel("Family-Based", "Center-Based")
  )
  
ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_ribbon(data = summary_table, aes(x = study_year, ymin = median_family_price, ymax = median_center_price, group = 1),
              fill = "skyblue", alpha = 0.3, inherit.aes = FALSE) +
  labs(
    title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
    subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
    x = "Year",
    y = "Median Weekly Price (2018 Dollars)",
    color = "Type of Childcare"
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(margin = margin(b = 10)),
    axis.title = element_text(face = "bold"),
    plot.background = element_rect(color = "black", linewidth = 1) 
  )

```

-   I can modify my colors to be accessible to anyone's eyes

```{r}
#| label: dvs-2-ex-2

# From Challenge 3, Question 2

# Here I use scale_fill_manual to explicitly change the colors on the bar chart to specific hexidecimal values.

# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

# I also modified the hex codes to be true tone, which is a color-blind safe color combination per https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40.

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#D81B60", "excellent" = "#1E88E5")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )

```

-   I can modify my plot titles to clearly communicate the data context

```{r}
#| label: dvs-2-ex-3


# Challenge 4
# I added a descriptive title, subtitle, x, and y axis titles to make the plot more readable.

summary_table_long <- summary_table |>
  pivot_longer(
    cols = c("median_center_price", "median_family_price"),
    names_to = "care_type",
    values_to = "median_price"
  ) |>
  mutate(
    care_type = fct_recode(care_type,
      "Center-Based" = "median_center_price",
      "Family-Based" = "median_family_price"
    ) |>
      fct_relevel("Family-Based", "Center-Based")
  )
  
ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_ribbon(data = summary_table, aes(x = study_year, ymin = median_family_price, ymax = median_center_price, group = 1),
              fill = "skyblue", alpha = 0.3, inherit.aes = FALSE) +
  labs(
    title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
    subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
    x = "Year",
    y = "Median Weekly Price (2018 Dollars)",
    color = "Type of Childcare"
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(margin = margin(b = 10)),
    axis.title = element_text(face = "bold"),
    plot.background = element_rect(color = "black", linewidth = 1) 
  )


```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-ex-4

# From Challenge 3, Question 2

# Here I use geom_text to add counts to the shaded sections of the bar chart.I also modify the x axis label to say the years of experience and added a title.

# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#ba945c", "excellent" = "#b796d4")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )


```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-ex-5

# Lab 4, Question 7
# Here I use fct_reorder to reorder the median incomes in decending order which will be later used as a color and therefore a legend in the subsequent plot.
  
long_childcare_data <- left_join(ca_childcare, income_table, by="region") |>
  select(study_year,
         region,
         mc_infant,
         mc_toddler,
         mc_preschool,
         `Median Income 2018`) |>
  pivot_longer(
    cols = starts_with("mc"),
    names_to = "age_group",
    values_to = "price"
  ) |>
  mutate(
    age_group = fct_recode(age_group,
    "Infant" = "mc_infant",
    "Toddler" = "mc_toddler",
    "Preschool" = "mc_preschool"
    ),
    age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
    region = fct_reorder(region, `Median Income 2018`, .desc = TRUE)
  )


pallete <- colorRampPalette(brewer.pal(7, "Accent"))(10)

ggplot(long_childcare_data, aes(x = study_year, y = price, color = region)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", alpha = 0.5) +
  facet_wrap(~ age_group, ncol=3) +
  labs(
    title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = NULL,
    color = "California Region"
  ) +
  scale_x_continuous(breaks = seq(from = 2008, to = 2018, by = 2)) +
  scale_color_manual(values = pallete) +
  theme(aspect.ratio = 1)

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors (Example 1)

```{r}
#| label: dvs-3-1-ex-1

# Challenge 4
# Here I used skyblue to denote the area / difference between the price of both care types.

ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_ribbon(data = summary_table, aes(x = study_year, ymin = median_family_price, ymax = median_center_price, group = 1),
              fill = "skyblue", alpha = 0.3, inherit.aes = FALSE) +
  labs(
    title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
    subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
    x = "Year",
    y = "Median Weekly Price (2018 Dollars)",
    color = "Type of Childcare"
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(margin = margin(b = 10)),
    axis.title = element_text(face = "bold"),
    plot.background = element_rect(color = "black", linewidth = 1) 
  )

```

-   I can use non-standard colors (Example 2)

```{r}
#| label: dvs-3-1-ex-2

# From Challenge 3

# In this example I specified custom colors for the plot using hex codes.

# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#ba945c", "excellent" = "#b796d4")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )

```

-   I can use annotations (e.g., `geom_text()`)

```{r}
#| label: dvs-3-2

# From Challenge 3 Question 2
# Here I use geom_text to add counts to the shaded sections of the bar chart.I also modify the x axis label to say the years of experience and added a title.

# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#ba945c", "excellent" = "#b796d4")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )



```

-   I can choose creative geometries (e.g., `geom_segment()`, `geom_ribbon)()`)

```{r}
#| label: dvs-3-3

# Challenge 4
# Here I used geom_ribbon to denote the price difference between family-based and center-based infant care costs.

ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  geom_ribbon(data = summary_table, aes(x = study_year, ymin = median_family_price, ymax = median_center_price, group = 1),
              fill = "skyblue", alpha = 0.3, inherit.aes = FALSE) +
  labs(
    title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
    subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
    x = "Year",
    y = "Median Weekly Price (2018 Dollars)",
    color = "Type of Childcare"
  ) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(margin = margin(b = 10)),
    axis.title = element_text(face = "bold"),
    plot.background = element_rect(color = "black", linewidth = 1) 
  )


```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

# Lab 3 Question 6

# In this example I use summarize to quickly compute and display the number of unique courses and teachers.

# This was revised from my initial submission which computed these values seperatly and returned them as individual values. The summary table is much more concise and readable.

teacher_evals_clean |>
  summarize(
    num_unique_teachers = n_distinct(teacher_id),
    num_unique_courses = n_distinct(course_id)
    )

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

# From Lab 7 Question 1
# Here across is used with summarise to calculate the number of missing values (a numerical summary) across everything in the fish data set.

missing_summary <- fish |>
  summarise(across(everything(), 
                   ~ sum(is.na(.x)), 
                   .names = "{col}_missing"))


```

\

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

# Lab 3 Question 9

# Here I grouped the teacher evaluations by course and teacher in order to find the number of teacher course combinations who asked all nine questions.

teacher_evals_clean |>
  group_by(course_id, teacher_id) |>
  summarize(number_of_questions = n_distinct(question_no)) |>
  filter(number_of_questions == 9) |>
  nrow()

```

-   Example 2

```{r}
#| label: dvs-5-2

# Lab 4 Question 5
# Here I created a summary table which works by grouping ca_childcare by region and study_year in order to compute the median 2018 inflation adjusted earnings.

# This particular code segment was revised; I added the "Median Income" prefix to make the column titles more descriptive.

income_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(
    median_income = median(me_2018),
  ) |>
  ungroup() |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_prefix = "Median Income "
  ) |>
  arrange(desc(`Median Income 2018`))


```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   I can modify my column names to clearly communicate the data context

```{r}
#| label: dvs-6-ex-1

# Lab 4 Question 5
# Here I used a names_prefix in pivot wider to make the data context more obvious.

# This particular code segment was revised. I added the "Median Income" prefix to make the column titles more descriptive.

income_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(
    median_income = median(me_2018),
  ) |>
  ungroup() |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_prefix = "Median Income "
  ) |>
  arrange(desc(`Median Income 2018`))

```

-   I can modify the text in my table to be more readable (e.g., bold face for column headers)

```{r}
#| label: dvs-6-ex-2

# Lab 10 Question 2
# Here I use fmt_percent to format the proportion colums as percentages which is more readable given the column is proportion.

enframe(results, name = NULL, value = "matches") |>
  count(matches) |> 
  mutate(proportion = n / sum(n)) |>
  gt() |>
  cols_label(
    matches = "Matches (Babies)",
    n = "Count",
    proportion = "Proportion"
  ) |>
  fmt_percent(
    columns = proportion, 
    decimals = 1
  )

```

\

-   I can arrange my table to have an intuitive ordering

```{r}
#| label: dvs-6-ex-3

# Lab 4 Question 5
# Here I created a summary table which displays regions and their median incomes for 2008 and 2018.
# This particular code segment was revised. I added the "Median Income" prefix to make the column titles more descriptive.

income_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(
    median_income = median(me_2018),
  ) |>
  ungroup() |>
  pivot_wider(
    names_from = study_year,
    values_from = median_income,
    names_prefix = "Median Income "
  ) |>
  arrange(desc(`Median Income 2018`))

```

**DVS-7: I show creativity in my tables.**

-   I can use non-default colors

```{r}
#| label: dvs-7-ex-1

# Lab 9, Question 8
# In this problem I created a summary table then added a header and colored the Missing Values count column to dark green or dark red.

missing_summary <- fish |>
  map_int(~ sum(is.na(.x))) |>
  enframe(name = "Measurement Variable", value = "Missing Values") |>
  gt()

missing_summary |>
  tab_header(
    title = "Number of Missing Values for Fish Measurements",
    subtitle = "Data Collected from 1989 to 2006 on the Blackfoot Fish River in Montana."
  ) |>
  tab_style(
    style = cell_fill(color = "darkgreen"),
    locations = cells_body(
      columns = `Missing Values`,
      rows = `Missing Values` == 0
    )
  ) |>
  tab_style(
    style = cell_fill(color = "darkred"), 
    locations = cells_body(
      columns = `Missing Values`,
      rows = `Missing Values` > 0
    )
  )


```

-   I can modify the layout of my table to be more readable (e.g., `pivot_longer()` or `pivot_wider()`)

```{r}
#| label: dvs-7-ex-2

# From Lab 9, Question 6
# Here I use pivot_longer and change the kable alignment to nicely group each column by demographic.

evals_factors |>
  distinct(teacher_id, .keep_all = TRUE) |>
  select(
    `Academic Degree` = academic_degree,
    Seniority = seniority,
    Sex = sex
  ) |>
  mutate(
    `Academic Degree` = fct_recode(`Academic Degree`,
      "Doctorate"         = "dr",
      "Masters"           = "ma",
      "No Degree"         = "no_dgr",
      "Tenured Professor" = "prof"
    ),
    Seniority = case_when(
      Seniority <= 4 ~ "Junior",
      Seniority <= 8 ~ "Senior",
      TRUE           ~ "Very Senior"
    ),
    Sex = fct_relabel(Sex, str_to_title)
  ) |>
  pivot_longer(cols = everything(), names_to = "variable", values_to = "level") |>
  count(variable, level) |>
  group_by(variable) |>
  mutate(prop = n / sum(n)) |>
  ungroup() |>
  mutate(prop = label_percent(accuracy = 0.1)(prop)) |>
  rename(
    "Demographic" = variable,
    "Group" = level,
    "Count" = n,
    "%" = prop
  ) |>
  kable(align = "llrr") |>
  kable_styling(full_width = FALSE) |>
  collapse_rows(columns = 1, valign = "top")

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

# Lab 4 Question 4

# Here I removed " County" from county_name and added a new column in one call to mutate rather than using two seperate piped calls to mutate

# This solution was revised from its initial submission. I removed the initial mutate for just county_name, and moved it into the mutate for collapsing into the region as an aditional argument.

ca_childcare <- ca_childcare |> 
  mutate(
    county_name = str_remove(county_name, " County"),
    region = fct_collapse(county_name,
      "Superior California" = superior_counties,
      "North Coast" = north_coast_counties,
      "San Francisco" = san_fran_counties,
      "Northern San Joaquin" = n_san_joaquin_counties,
      "Central Coast" = central_coast_counties,
      "Southern San Joaquin" = s_san_joaquin_counties,
      "Inland Empire" = inland_counties,
      "Los Angeles" = la_county,
      "Orange County" = orange_county,
      "San Diego Imperial" = san_diego_imperial_counties
    )
  )

```

-   using `across()`

```{r}
#| label: pe-1-across

# Lab 3 Question 5
# In this problem I used across to convert 6 columns to a factor in one function call.

# I modified this from the original to use modern lambda syntax.

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 9) |>
  mutate(
    across(c(academic_degree,
             sex,
             weekday,
             course_id,
             teacher_id,
             question_no),
           ~ as.factor(.)),
  ) |>
  select(
    course_id,
    teacher_id,
    question_no,
    no_participants,
    resp_share,
    SET_score_avg,
    percent_failed_cur,
    academic_degree,
    seniority,
    sex
  )

```

-   using functions from the `map()` family

```{r}
#| label: pe-1-map-1

# From Lab 10, Question 1
# Here I used map_int to perform 10000 random samples and store the result of each.

randomBabies <- function(n_babies) {
  # The correct sequence i.e. 1,2, 3, ... , n_babies
  correct_assignment <- 1:n_babies
  
  shuffled_assignment <- sample(correct_assignment)
  
  # How many babies in correct order for each sample.
  return(sum(correct_assignment == shuffled_assignment))
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(n_babies = 4)
                  )


```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Function that operates on vectors

```{r}
#| label: pe-2-1

# From Lab 7, Question 4
# In this problem I created the rescale_01 function which takes a numerical vector and rescales it.

rescale_01 <- function(vector) {
  
  if (!is.numeric(vector)) {
    stop("Input vector must be numeric.")
  }
  
  if (length(vector) <= 1) {
    stop("Input vector must have more than one element to calculate a range.")
  }
  
  min_val <- min(vector, na.rm = TRUE)
  max_val <- max(vector, na.rm = TRUE)
  
  (vector - min_val) / (max_val - min_val)
}

```

-   Example 2: Function that operates on data frames

```{r}
#| label: pe-2-2

# From Lab 8, Question 2
# In this problem I created a function called pivot_table which counts the number of observations for each combination of the two variables and then puts it into a human-redable dataframe and returns it.

pivot_table <- function(df, row_var, col_var) {
  
  if (!is.data.frame(df)) {
    stop("The first argument 'df' must be a data frame.")
  }
  
  df |>
    count({{ row_var }}, {{ col_var }}) |>
    pivot_wider(
      names_from = {{ col_var }},
      values_from = n,
      values_fill = 0
    ) |>
    adorn_totals(where = c("row", "col"))
    
}

```

-   Example 3: Function that operates on vectors *or* data frames

```{r}
#| label: pe-2-3

# From Lab 8, Question 3
# In this problem I created the create_colored_scatterplot function which takes a data frame, x variable, and y vaiable and returns a minimally styled plot plotting y against x.

format_name <- function(var_quo) {
    
    var_name <- rlang::as_name(var_quo)
    var_name |>
      stringr::str_replace_all("_", " ") |>
      stringr::str_to_title()
    
}

create_colored_scatterplot <- function(df, x_var, y_var) {
  
  x_var_quo <- enquo(x_var)
  y_var_quo <- enquo(y_var)
  
  x_lab <- format_name(x_var_quo)
  y_lab <- format_name(y_var_quo)
  
  ggplot(
    data = df,
    mapping = aes(x = {{ x_var }}, y = {{ y_var }})
  ) +
    geom_point(
      mapping = aes(color = {{ y_var }}), 
      show.legend = FALSE,
      alpha = 0.8
    ) +
    scale_color_viridis_c() +
    labs(
      title = paste(y_lab, "vs.", x_lab),
      x = x_lab,
      y = y_lab,
    ) +
    theme_minimal()
}

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   using `across()`

```{r}
#| label: pe-3-across

# Lab 8 Question 1
# Here I used the across function to apply my rescale_01 function across all colums.

rescale_01 <- function(vector) {
  
  if (!is.numeric(vector)) {
    stop("Input vector must be numeric.")
  }
  
  if (length(vector) <= 1) {
    stop("Input vector must have more than one element to calculate a range.")
  }
  
  min_val <- min(vector, na.rm = TRUE)
  max_val <- max(vector, na.rm = TRUE)
  
  (vector - min_val) / (max_val - min_val)
}

rescale_column <- function (df, cols) {
  df |>
    mutate(across({{cols}}, rescale_01))
}

```

-   using a `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

# From Lab 10, Question 10
# Here I used a map to to effectively execute mycifun one thousands times and store the result of each.

mycifun <- function(beta0, beta1, n) {
  
  x = runif(n = n, min = 0, max = 1)
  
  ep = rnorm(n = n, mean = 0, sd = 1)
  
  y = beta0 + beta1 * x + ep
  
  obs_data <- data.frame(x = x, y = y)
  
  fit <- lm(y ~ x, data = obs_data)
  
  tidy(fit, conf.int = TRUE) |>
    filter(term == "x") |>
    mutate(cover = ifelse(conf.low <= beta1 & beta1 <= conf.high, 1, 0)) |>
    select(estimate, conf.low, conf.high, cover)
  
}

ci_dat <- map(.x = 1:1000,
              .f = ~ mycifun(beta0 = 3, beta1 = 0.5, n = 100)
              )

```

-   using a `map()` function with **one** input

```{r}
#| label: pe-3-map-2

# From Lab 9 Question 2
# Here I use map_chr(typeof) to get the data type of each variable in the surveys dataset.

data_types <- surveys |>
  map_chr(typeof) |>
  enframe(name = "Variable",
          value = "Data Type")

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

# Challenge 3 Question 2

# I modified this from the original: I changed scales::percent to the non-deprecated scales::label_percent().

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level, fill = SET_level)) +
  geom_bar(position = "fill") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    position = position_fill(vjust = 0.5),
    size = 3.5
  ) +
  theme_minimal() +
  theme(legend.position = "top", panel.border = element_rect(color = "black")) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_fill_manual(values = c("standard" = "#ba945c", "excellent" = "#b796d4")) +
  labs(
    x = "Years of Experience",
    y = NULL,
    fill = "Evaluation Rating",
    title = "Evaluation of Teachers' Use of Activities"
  )

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

# Challenge 4

# Here I used dplyr to "wrangle" the summary table and then use that table within ggplot.

# I modified this from the original to connect the summary table direclty to ggplot with a pipe

summary_table |>
  pivot_longer(
    cols = c("median_center_price", "median_family_price"),
    names_to = "care_type",
    values_to = "median_price"
  ) |>
  mutate(
    care_type = fct_recode(care_type,
      "Center-Based" = "median_center_price",
      "Family-Based" = "median_family_price"
    ) |>
      fct_relevel("Family-Based", "Center-Based")

  ) |>
  ggplot(summary_table_long, aes(x = study_year, y = median_price, color = care_type)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 3) +
    geom_ribbon(data = summary_table,
                aes(x = study_year,
                    ymin = median_family_price,
                    ymax = median_center_price,
                    group = 1),
              fill = "skyblue",
              alpha = 0.3,
              inherit.aes = FALSE) +
    labs(
      title = "Median Weekly Infant Childcare Costs in California (2008-2018)",
      subtitle = "Based off the aggregated median price for each care type on an annual basis in various California counties.",
      x = "Year",
      y = "Median Weekly Price (2018 Dollars)",
      color = "Type of Childcare"
    ) +
    scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "top",
      plot.title = element_text(face = "bold"),
      plot.subtitle = element_text(margin = margin(b = 10)),
      axis.title = element_text(face = "bold"),
      plot.background = element_rect(color = "black", linewidth = 1) )


```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

# From Lab 10, Question 1
# Here I used map_int to perform 10000 random samples and store the result of each.

randomBabies <- function(n_babies) {
  # The correct sequence i.e. 1,2, 3, ... , n_babies
  correct_assignment <- 1:n_babies
  
  shuffled_assignment <- sample(correct_assignment)
  
  # How many babies in correct order for each sample.
  return(sum(correct_assignment == shuffled_assignment))
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(n_babies = 4)
                  )

```

-   Example 2

```{r}
#| label: dsm-1-2

# From Lab 10, Question 10
# Here I used map to generate synthetic datasets by sampling X from a Uniform distribution and errors from a Normal distribution.

mycifun <- function(beta0, beta1, n) {
  
  x = runif(n = n, min = 0, max = 1)
  
  ep = rnorm(n = n, mean = 0, sd = 1)
  
  y = beta0 + beta1 * x + ep
  
  obs_data <- data.frame(x = x, y = y)
  
  fit <- lm(y ~ x, data = obs_data)
  
  tidy(fit, conf.int = TRUE) |>
    filter(term == "x") |>
    mutate(cover = ifelse(conf.low <= beta1 & beta1 <= conf.high, 1, 0)) |>
    select(estimate, conf.low, conf.high, cover)
  
}

ci_dat <- map(.x = 1:1000,
              .f = ~ mycifun(beta0 = 3, beta1 = 0.5, n = 100)
              )



```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

# Lab 4 Question 9
# Here I used lm to fit a linear regression model to the relationship between infant childcare Price and the median household income in California.

reg_mod1 <- lm(mc_infant ~ mhi_2018, data = ca_childcare)

summary(reg_mod1)
```

-   Example 2

```{r}
#| label: dsm-2-2

# Lab 1 Question 10

# Here I used a two sample t-test to compare the mean tooth length for the OJ supplement delivery method and the treatment method.

t.test(len ~ supp, data = ToothGrowth, var.equal = FALSE)

## Two Sample T Test For Tooth Growth Data

## 1. Given p = 0.06063 >  = 0.05, there is insufficient statistically significant evidence to reject the hypothesis that treatment mean tooth length for the OJ supplement delivery method  is the same as the treatment mean tooth length for the VC supplement delivery method.

## 2. Given a 95% confidence interval of (-0.1710156, 7.5710156) we are 95% confident the difference between tooth length true difference in means between group OJ and group VC is between -0.171015 and 7.5710156. Since this interval contains zero, we cannot assert the group population means are likely different.

```

-   Example 3

```{r}
#| label: dsm-2-3

```

## Revising My Thinking

Throughout the course I received a wide array of feedback ranging from correctness, code neatness, providing context to data, reducing repetition in my code, and more. For the sake of demonstration my ability to revise my thinking I am going to focus on how I was able to reduce repetition in my code following feedback.\
The two examples of revision I will cite is Lab 3 Question 6 (**dvs-4-summarize**) and Lab 4 Question 4 (**pe-1-one-call)**, both of which are referenced in this portfolio. If you scroll below you can see what both code segments looked like before. For lab 4 question 4, there was a duplicate mutate and pipe which was not necessary to modify the county_name before collapsing it into regions. My revision was simply performing this modification using an additional argument in the other mutate rather than adding a whole new pipe and mutate. Additionally, I revised lab 3 question 6 in order to improve code repetition. In this more egregious example I used two separate dplyr pipelines to extract the number of unique courses and unique teachers in the data frame. After receiving feedback I modified the solution to compute both values in a single summary table as two different columns.

More importantly than just blindly implementing these changes, I learned the importance of reducing code repetition: these documents are supposed to be a reproducible report, and intended to be easily understandable by the reader. Non-repetitive code reduces the mental burden of the reader and allows them to focus on what matters, the analysis. Learning the tips and tricks is one thing, but gaining a mindset of reducing repetition is whats far more valuable side-effect of these revisions.

Lab 4 Question 4 Before Revision:

![](images/clipboard-3145997561.png)

Lab 3 Question 6 Before Revision:

![](images/clipboard-3405513232.png)

## Extending My Thinking

\
\
Throughout the labs and challenges I have had several opportunities to extend my thinking. Most questions in the labs provided a lot of guidance so I could garner a foundation. However, some questions such as Lab 4 Question 7 gave us opportunities to our extend our thinking by serving as multi-step, non-obvious questions. This lab question in particular forced me to think outside the box and find outside resources to solve the problem. More specifically, in attempting to match the color palette I came across the [colorRampPallete](https://www.rdocumentation.org/packages/dichromat/versions/1.1/topics/colorRampPalette) R documentation. I didn't recall learning this in class, so I had to extend my thinking by understanding these docs and doing my best to match the color theme of the plot.

However, I found the challenges to be the best way to extend my thinking. The labs provided a great base to learn the foundation skills, then I could combine those skills with what I learn from additional research. The best illustration of this is my repeated use of Challenge #4 throughout my portfolio. In this challenge I identified a research question: How has the median price of full-time, center-based infant childcare in California compared to that of family-based infant childcare, and has the price gap between these two options widened or narrowed between 2008 and 2018? I realized that the difference between the two median costs when extrapolated across the time series creates an area representing the price differential. However, up to this point in the course, we hadn't used an area plot and was unfamiliar with how to plot the plot area between two lines in ggplot. So I googled that question, and came across [geom_ribbon](https://ggplot2.tidyverse.org/reference/geom_ribbon.html) which I incorporated into my plot and subsequent analysis.

## Peer Support & Collaboration

![](images/clipboard-3327786451.png)

![](images/clipboard-3713802392.png)

Above are two examples of when I provided peer feedback in the Discord channel. I am proud of these in particular as I was able to provide quick feedback to problems that could have left my peers stuck. Particularly, for the first example I feel like I did a good job of not giving the answer but guiding towards it so that my peer could still learn from the problem.\
\
The weekly pair programming activities were eye an opening, and well-designed learning experience. Namely, the forced separation into two distinct roles helped me learn about myself and learn course outcomes more effectively. Being forced to be passive, I found that I have a real tendency to speak up as to avoid awkward silence, a tendency which can really hurt the group problem solving process. Giving my partner the time to think, and waiting until they express a willingness to discuss the problem gave them the time and space to reason through a problem. This also allowed me to learn new approaches to problems such as using if_all in PA 4 Problem 3. If I were to break the silence and interject, we could've ended up with my solution which was far worse an involved enumerating every column and using is.na().
